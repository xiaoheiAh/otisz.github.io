<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>Redis-复制功能探索 - xiaoheiAh's blog</title><link rel=icon type=image/png href=https://blog.xiaohei.im/favicon.ico><meta name=viewport content="width=device-width,initial-scale=1"><meta property="og:title" content="Redis-复制功能探索"><meta property="og:description" content="「Redis 学习笔记」| HA | 高可用 | 主从复制"><meta property="og:type" content="article"><meta property="og:url" content="https://blog.xiaohei.im/posts/redis/replication/"><meta property="article:published_time" content="2019-11-16T14:24:40+08:00"><meta property="article:modified_time" content="2019-11-16T14:24:40+08:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Redis-复制功能探索"><meta name=twitter:description content="「Redis 学习笔记」| HA | 高可用 | 主从复制"><link rel=stylesheet type=text/css media=screen href=https://blog.xiaohei.im/css/normalize.css><link rel=stylesheet type=text/css media=screen href=https://blog.xiaohei.im/css/main.css><link rel=stylesheet href="https://fonts.loli.net/css2?display=swap&family=Bitter&family=Noto+Sans+SC"><link rel=stylesheet type=text/css href=https://blog.xiaohei.im/css/dark.css media="(prefers-color-scheme: dark)"><script src=https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js></script><script src=https://blog.xiaohei.im/js/main.js></script></head><body><div class="container wrapper post"><div class=header><h1 class=site-title><a href=https://blog.xiaohei.im/>xiaoheiAh's blog</a></h1><div class=site-description><h2>Java Developer | 关注后端</h2><nav class="nav social"><ul class=flat><a href=https://github.com/xiaoheiAh title=xiaoheiAh><i data-feather=github></i></a></ul></nav></div><nav class=nav><ul class=flat><li><a href=/>Home</a></li><li><a href=/posts>All posts</a></li><li><a href=/tags>Tags</a></li><li><a href=/awesome>Awesome</a></li><li><a href=/cheatsheet>CheatSheet</a></li><li><a href=/about>About</a></li></ul></nav></div><div class=post-header><h1 class=title>Redis-复制功能探索</h1><div class=meta style=display:inline>Posted at &mdash; Nov 16, 2019</div><div class=meta style=display:inline><a>Page Views: 3</a></div></div><div class=markdown><p>之前对<code>redis</code> 的复制只有一点点了解,这次想要搞明白的是:如何实现的复制? 复制会遇到哪些问题(时延/一致性保证/网络故障时的处理)? 如何解决?高可用实现方案?</p><p>文章有部分是直接翻译的 <a href=https://redis.io/topics/replication>https://redis.io/topics/replication</a></p><h2 id=复制是什么>复制是什么?</h2><p>分布式系统有一个重要的点时保证数据不丢失,数据不丢失就意味着不能单点,不能单点就意味着最好能把数据多存几份形成数据的冗余.这就是复制的来由.复制类型主要是两种: <strong>同步</strong>, <strong>异步</strong>. 前者需要等待所有的节点返回写入确认,后者只需要返回个确认收到就行.</p><h2 id=redis-主从复制>Redis 主从复制</h2><h3 id=主从复制作用>主从复制作用</h3><ol><li><strong>数据冗余</strong>:主从复制实现了数据的热备份,是持久化之外的一种数据冗余方式。</li><li><strong>故障恢复</strong>:当主节点出现问题时,可以由从节点提供服务,实现快速的故障恢复;实际上是一种服务的冗余。</li><li><strong>负载均衡</strong>:在主从复制的基础上,配合读写分离,可以由主节点提供写服务,由从节点提供读服务(即写Redis数据时应用连接主节点,读Redis数据时应用连接从节点),分担服务器负载;尤其是在写少读多的场景下,通过多个从节点分担读负载,可以大大提高Redis服务器的并发量。</li><li><strong>高可用基石</strong>:除了上述作用以外,主从复制还是哨兵和集群能够实施的基础,因此说主从复制是Redis高可用的基础。</li></ol><h3 id=redis-复制设计要点>Redis 复制设计要点</h3><ul><li><p>默认使用异步复制 &ndash; replica -> master 异步返回处理了多少数据的结果(<strong>偏移量</strong>)</p></li><li><p><code>master</code> 可以多 <code>replicas</code></p></li><li><p><code>replicas</code> 可以从其他 <code>replica</code> 同步(从从复制).类似于级联更新的架构.</p><p><img src=https://cdn.jsdelivr.net/gh/xiaoheiAh/imgs@master/20191118110202.png alt=从从复制></p></li><li><p><code>master</code> 主节点在同步时不会阻塞.</p></li><li><p>在 <code>replica</code> 侧复制也是非阻塞的.在进行初始化同步(全量)时,可以使用 <code>replica</code>上的旧数据供客户端查询.也可以在 <code>redis.conf</code> 进行配置,在初始化同步完成前客户端的请求都报错.初始化同步完成后,需要删除老数据,加载新数据.在这段时间中会阻塞外部连接请求,数据量大的话可能要很久.从 <code>4.0</code> 版本后,删除老数据可以通过多线程来优化效率,但是加载新数据还是会 <strong>阻塞</strong>.</p></li><li><p>复制可以用来弹性扩容,提供多可读副本,提升数据安全性,保证高可用</p></li><li><p>副本可以避免 <code>master</code> 保存全量数据到磁盘的资源消耗:可以由 <code>replica</code> 完成持久化,或者开启 <code>aof</code> 写入.不过需要慎重: 这样会导致 <code>master</code> 节点再重启时会是空的,其他 <code>replica</code>复制时也就成空的了.</p></li></ul><h3 id=主从复制过程>主从复制过程</h3><p>每一个 <code>master</code> 节点都会有一个特别大的随机数(40字节十六进制随机字符)作为 <code>replication ID</code> 来标识自己.每个 <code>master</code> 节点也有一个 持续递增的 <code>offset</code> 来记录发送给 <code>replicas</code> 的每一个 <code>byte</code>,利用该 <code>offset</code> 来保证副本更新的状态.</p><p>当一个 <code>replica</code> 连接到 <code>master</code> 时,会使用 <code>PSYNC</code> 命令发送之前复制的 <code>master</code> 的 <code>replicationID</code>,以及自己的更新进度(<code>offset</code>).<code>master</code> 可以根据这个值给副本按需返回为更新的数据.如果在<code>master</code> 的 <code>backlog buffer</code> 中没有对应的数据可以给到,副本发送的 <code>replicationID</code> 与 <code>master</code> 的 ID 不一致,就会触发全量复制(<code>Full Synchronization</code>).</p><h4 id=backlog-buffer-是啥>backlog buffer 是啥?</h4><p>复制积压缓冲区,在 <code>master</code> 有 <code>replica</code> 进行复制时,存储 <code>master</code> 最近一段时间的写命令,以便在 <code>replica</code> 断开重连后,可以利用缓冲区更新断开这段时间中,从节点丢掉的更新.</p><p><code>backlog buffer</code> 是有固定的长度,先进先出的队列,默认大小 <code>1MB</code>. 其实就是一个环.<code>buffer</code> 会存储每一个 <code>offset</code> 已经对应的写命令,这样 <code>replica</code> 在断连恢复后,发送 <code>PSYNC</code> 命令提供其最后一次更新的 <code>offset</code>, <code>master</code> 就可以根据 <code>replica</code> 提供的 <code>offset</code> 去 <code>buffer</code> 中找对应的数据发送给 <code>replica</code> 保持最新.</p><p>如果断开时间过长,<code>buffer</code> 存储的数据已经换了一批又一批, <code>replica</code> 在重连后发送给 <code>master</code> 的 <code>offset</code> 在 <code>buffer</code> 已经找不到了.此时会触发 <strong>全量复制</strong>.</p><h4 id=全量复制>全量复制</h4><p><code>master</code>调用 <code>bgsave</code> 在后台生成 <code>rdb</code> 文件.同时记录客户端新的写命令到 <code>backlog buffer</code> 中. <code>rdb</code> 文件生成后,发送给 <code>replica</code> 保存到其硬盘中,然后再加载到内存中并通知<code>master</code> 加载完成.然后 <code>master</code> 会发送 <code>buffer pool</code> 中的命令给 <code>replica</code> 完成最后的同步.</p><h4 id=syncpsync>SYNC/PSYNC</h4><p>两者都是同步的命令.<code>SYNC</code> 只支持全量同步, <code>PSYNC</code> 支持上述的部分同步.<code>2.8</code> 版本之前只有 <code>SYNC</code>,为了避免每次都只能全量同步造成资源的浪费,就新增了 <code>PSYNC</code> 命令实现部分同步的语义.</p><h4 id=replication-id>Replication ID</h4><p><code>Replication ID</code> 标记了数据的历史信息,从0开始成为<code>master</code> 的节点,或者晋升成为 <code>master</code> 的 <code>replica</code> 节点,都会生成一个 <code>Replication ID</code>.<code>replicas</code> 的 <code>replId</code> 是和其复制的 <code>master</code> 一致的,<code>master</code> 通过该 ID 和 <code>offset</code> 来判断主从之间数据是否一致.</p><h5 id=为什么有两个replid>为什么有两个<code>replId</code>?</h5><div class=highlight><pre style=color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=color:#586e75>/* src/server.h */</span>
<span style=color:#719e07>struct</span> redisServer {
  ...
  <span style=color:#586e75>/* Replication (master) */</span>
  <span style=color:#dc322f>char</span> replid[CONFIG_RUN_ID_SIZE<span style=color:#719e07>+</span><span style=color:#2aa198>1</span>];  <span style=color:#586e75>/* My current replication ID. */</span>
  <span style=color:#dc322f>char</span> replid2[CONFIG_RUN_ID_SIZE<span style=color:#719e07>+</span><span style=color:#2aa198>1</span>]; <span style=color:#586e75>/* replid inherited from master*/</span>
  ...
  <span style=color:#dc322f>long</span> <span style=color:#dc322f>long</span> master_repl_offset;   <span style=color:#586e75>/* My current replication offset */</span>
  <span style=color:#dc322f>long</span> <span style=color:#dc322f>long</span> second_replid_offset; <span style=color:#586e75>/* Accept offsets up to this for replid2. */</span>
  ...
}
</code></pre></div><p>一般情况下,故障转移(<code>failover</code>)后,晋升的 <code>replica</code> 需要记录自己之前复制的 <code>master</code> 对应的 <code>replId</code>.其他 <code>replicas</code> 会向新 <code>master</code> 进行部分同步,但发送过来的 <code>replId</code> 还是之前 <code>master</code> 的.所以 <code>replica</code> 在晋升时,会生成新的<code>replId</code>,并将原来的 <code>replId</code> 记录到 <code>replId2</code>,同时记录下当时所更新到的 <code>offset</code> 到 <code>second_replid_offset</code>.当其他的 <code>replica</code> 向新 <code>master</code> 进行连接时,新 <code>master</code> 会比较当前的和之前 <code>master</code> 的 <code>replId</code>,<code>offset</code>,这样就可以防止在故障转移后导致不必要的 <strong>全量复制</strong>.</p><h5 id=为什么晋升后需要生成新-replid>为什么晋升后需要生成新 replId?</h5><p><code>old master</code> 可能还存活,但由于网络分区原因无法和其他 <code>replicas</code> 通信,如果保留原来的 <code>id</code> 不再生成,就会导致有相同数据相同id的<code>master</code> 存在.</p><h4 id=无盘复制>无盘复制</h4><p>全量复制时,<code>master</code> 会创建 <code>rdb</code> 文件存到磁盘,然后再读取 <code>rdb</code> 文件发送给 <code>replicas</code>.磁盘性能差的情况下,效率会很低,所以支持了 <strong>无盘复制</strong> &ndash; 子进程直接发送 <code>rdb</code> 给 <code>replicas</code>,不经过硬盘存储.</p><h4 id=如何处理可以过期的键>如何处理可以过期的键?</h4><ol><li>副本不会主动去过期键,而是由 <code>master</code> 过期键后向副本发送 <code>DEL</code> 命令.</li><li>由于是通过 <code>master</code> 驱动,副本收到 <code>DEL</code> 命令可能有延迟,这就会导致从副本中还可能查到已过期的键.针对这种情况,副本会利用自身的物理时钟作为依据报告该键不存在(仅在不违反数据一致性的 <strong>只读操作</strong>),因为 <code>DEL</code> 命令总是会发过来的.</li><li><code>LUA</code> 脚本执行期间,是不会去执行 <code>key</code> 过期的.脚本执行期间相当于 <code>master</code> 时间冻结了,不作过期时间的记录,所以在这期间过期键只有存在或不存在的概念.这样可以防止键在执行期间过期.同时,<code>master</code> 也需要发送同样的脚本给副本,保持一致.</li></ol><p>如果<code>replica</code> 晋升 <code>master</code> 了,它就会自己去处理键的过期了.</p><h4 id=心跳机制>心跳机制</h4><p>在正常的进行 <strong>部分同步</strong> 期间,主从之间会维持心跳,来协助超时判断,数据安全等问题.</p><h5 id=master---slave>master -> slave</h5><p>主节点发送 <code>PING</code> ,从节点回复 <code>PONG</code>.目的是让从节点进行超时判断.发送频率有 <code>repl-ping-slave-period</code> 参数控制.单位秒,默认 <code>10s</code>.</p><h5 id=replica---master>replica -> master</h5><p>从节点向主节点发送 <code>REPLCONF ACK {offset}</code> ,频率每秒1次.作用:</p><ol><li>试试检测主从网络状态,该命令被主节点用于复制超时的判断.</li><li>检测命令丢失,主节点会比较从节点发送的 <code>offset</code> 与自身的是否一致,不一致则从 <code>buffer</code> 中查找对应数据进行补发,如果 <code>buffer</code> 中没有对应数据,则会进行全量复制.</li><li>辅助保证从节点的数量和延迟,<code>master</code> 通过 <code>min-salves-to-write</code> 和 <code>min-slaves-max-lag</code> 参数,来保证主节点在不安全情况下不会执行写命令.是指从节点数量太少,或延迟过高。例如 <code>min-slaves-to-write</code> 和<code>min-slaves-max-lag</code> 分别是3和10,含义是如果从节点数量小于3个,或所有从节点的延迟值都大于10s,则主节点拒绝执行写命令。</li></ol><h2 id=复制惨痛案例>复制惨痛案例</h2><h4 id=数据过期问题>数据过期问题</h4><p>数据删除没有及时同步到从节点,其实在 <code>3.2</code> 版本后避免了这个问题.从节点会对键进行判断,已过期不展示.</p><p><a href=#%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E5%8F%AF%E4%BB%A5%E8%BF%87%E6%9C%9F%E7%9A%84%E9%94%AE?>如何处理可以过期的键?</a></p><h4 id=数据延迟不一致>数据延迟不一致</h4><p>这种情况不可避免.可能的优化措施包括:优化主从节点之间的网络环境(如在同机房部署);监控主从节点延迟通过<code>offset</code>判断,如果从节点延迟过大,通知应用不再通过该从节点读取数据;使用集群同时扩展写负载和读负载等。</p><h4 id=复制超时导致复制中断>复制超时导致复制中断</h4><h5 id=为什么要判断超时>为什么要判断超时?</h5><ol><li><code>master</code> 在判断超时后,会释放从节点的连接,释放资源.</li><li>断开后即时重连</li></ol><h5 id=判断机制>判断机制?</h5><p>核心参数: <code>repl-timeout</code> ,默认 60s.</p><p>(1)主节点:每秒1次调用复制定时函数replicationCron(),在其中判断当前时间距离上次收到各个从节点 <code>REPLCONF ACK</code> 的时间,是否超过了 <code>repl-timeout</code> 值,如果超过了则释放相应从节点的连接。</p><p>(2)从节点:从节点对超时的判断同样是在复制定时函数中判断,基本逻辑是:</p><ul><li>如果当前处于连接建立阶段,且距离上次收到主节点的信息的时间已超过 <code>repl-timeout</code>,则释放与主节点的连接；</li><li>如果当前处于数据同步阶段,且收到主节点的 <code>RDB</code> 文件的时间超时,则停止数据同步,释放连接;</li><li>如果当前处于命令传播阶段,且距离上次收到主节点的 <code>PING</code> 命令或数据的时间已超过repl-timeout值,则释放与主节点的连接。</li></ul><h5 id=问题>问题</h5><ol><li>全量复制时,如果 <code>RDB</code> 文件过大,耗时很长就会触发超时,此时从节点会重连,再生成<code>RDB</code>,再超时,在生成<code>RDB</code>&mldr;解决方案就是单机数据量尽量不要太大,增大 <code>repl-timeout</code>.</li><li>慢查询导致服务器阻塞: <code>keys *</code>,<code>hgetall</code></li></ol><h4 id=backlog-过小导致无限全量复制>backlog 过小导致无限全量复制</h4><p><code>backlog buffer</code> 是固定大小的,写入命令超出长度就会覆盖.如果再全量复制的时候用时超长,存入<code>buffer</code> 的命令超过了其大小限制,那么就会导致连接中断,再重连,全量复制,连接中断,全量复制&mldr;.死循环.解决方案就是需要正确设置 <code>backlog buffer</code> 的大小. 通过 <code>client-output-buffer-limit slave {hard limit} {soft limit} {soft seconds}</code> 配置,默认值为 <code>client-output-buffer-limit slave 256MB 64MB 60</code>,其含义是:如果 <code>buffer</code> 大于<code>256MB</code>,或者连续 <code>60s</code> 大于 <code>64MB</code> ,则主节点会断开与该从节点的连接。该参数是可以通过 <code>config set</code> 命令动态配置的(即不重启Redis也可以生效).</p><h2 id=参考>参考</h2><ol><li><p><a href=https://www.cnblogs.com/kismetv/p/9236731.html>深入学习Redis（3）：主从复制</a></p></li><li><p>「Redis 设计与实现」</p></li><li><p><a href=https://redis.io/topics/replication>https://redis.io/topics/replication</a></p></li></ol></div><div class=post-tags><nav class="nav tags"><ul class=flat><li><a href=/tags/redis>redis</a></li></ul></nav></div><script src=https://utteranc.es/client.js repo=xiaoheiAh/xiaoheiAh.github.io issue-term=pathname theme=github-light crossorigin=anonymous async></script></div><div class="footer wrapper"><nav class=nav><div class=badge><img src=https://img.shields.io/badge/PV-6232-green alt=pv>
<img src=https://img.shields.io/badge/UV-1767-green alt=uv>
<img src="https://img.shields.io/badge/License-CC%20BY%20NC%20ND%204.0-green?link=http://creativecommons.org/licenses/by-nc-nd/4.0/" alt="CC BY NC ND 4.0">
<span>| © 2019 | <a href=https://github.com/vividvilla/ezhil>Ezhil theme</a> | Built with <a href=https://gohugo.io>Hugo</a></span></div></nav></div><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-98254666-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><script>feather.replace()</script></body></html>